{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unet import resnet50_unet\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from PIL import Image\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NCLASSES = 3\n",
    "HEIGHT = 416\n",
    "WIDTH = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(lines,batch_size):\n",
    "    # 获取总长度\n",
    "    n = len(lines)\n",
    "    i = 0\n",
    "    while 1:\n",
    "        X_train = []\n",
    "        Y_train = []\n",
    "        # 获取一个batch_size大小的数据\n",
    "        for _ in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(lines)\n",
    "            name = lines[i].split(';')[0]\n",
    "            # 从文件中读取图像\n",
    "            img = Image.open(r\"F:\\AAshuju\\weed\\cropweeds\\input\\train\\images\" + '\\\\' + name)\n",
    "            img = img.resize((WIDTH,HEIGHT))\n",
    "            img = np.array(img)\n",
    "            img = img/255\n",
    "            X_train.append(img)\n",
    "\n",
    "            name = (lines[i].split(';')[1]).replace(\"\\n\", \"\")\n",
    "            # 从文件中读取图像\n",
    "            img = Image.open(r\"F:\\AAshuju\\weed\\cropweeds\\input\\train\\masks_n\" + '\\\\' + name)\n",
    "            img = img.resize((int(WIDTH/2),int(HEIGHT/2)))\n",
    "            img = np.array(img)\n",
    "            seg_labels = np.zeros((int(HEIGHT/2),int(WIDTH/2),NCLASSES))\n",
    "            for c in range(NCLASSES):\n",
    "                seg_labels[: , : , c ] = (img[:,:] == c ).astype(int)\n",
    "            seg_labels = np.reshape(seg_labels, (-1,NCLASSES))\n",
    "            Y_train.append(seg_labels)\n",
    "\n",
    "            # 读完一个周期后重新开始\n",
    "            i = (i+1) % n\n",
    "        yield (np.array(X_train),np.array(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# IOU\n",
    "def Mean_IOU(y_true, y_pred):\n",
    "    nb_classes = 3 #K.int_shape(y_pred)[-1]\n",
    "    iou = []\n",
    "    true_pixels = K.argmax(y_true, axis=-1)\n",
    "    pred_pixels = K.argmax(y_pred, axis=-1)\n",
    "    void_labels = K.equal(K.sum(y_true, axis=-1), 0)\n",
    "    for i in range(0, nb_classes): # exclude first label (background) and last label (void)\n",
    "        true_labels = K.equal(true_pixels, i) & ~void_labels\n",
    "        pred_labels = K.equal(pred_pixels, i) & ~void_labels\n",
    "        inter = tf.to_int32(true_labels & pred_labels)\n",
    "        union = tf.to_int32(true_labels | pred_labels)\n",
    "        legal_batches = K.sum(tf.to_int32(true_labels), axis=1)>0\n",
    "        ious = K.sum(inter, axis=1)/K.sum(union, axis=1)\n",
    "        iou.append(K.mean(tf.gather(ious, indices=tf.where(legal_batches)))) # returns average IoU of the same objects\n",
    "    iou = tf.stack(iou)\n",
    "    legal_labels = ~tf.debugging.is_nan(iou)\n",
    "    iou = tf.gather(iou, indices=tf.where(legal_labels))\n",
    "    return K.mean(iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "log_dir = \"logs/\"\n",
    "# 获取model\n",
    "model = resnet50_unet(n_classes=NCLASSES,input_height=HEIGHT, input_width=WIDTH)\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#打开数据集的txt\n",
    "with open(r\"F:\\AAshuju\\weed\\cropweeds\\input\\train\\train.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# 打乱行，这个txt主要用于帮助读取数据来训练\n",
    "# 打乱的数据更有利于训练\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 80%用于训练，20%用于估计。\n",
    "num_val = int(len(lines)*0.2)\n",
    "num_train = len(lines) - num_val\n",
    "\n",
    "# 保存的方式，1世代保存一次\n",
    "checkpoint_period = ModelCheckpoint(\n",
    "                                log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "                                monitor='val_loss', \n",
    "                                save_weights_only=True, \n",
    "                                save_best_only=True, \n",
    "                                period=1\n",
    "                             )\n",
    "# 学习率下降的方式，val_loss三次不下降就下降学习率继续训练\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "                        monitor='val_loss', \n",
    "                        factor=0.5, \n",
    "                        patience=3, \n",
    "                        verbose=1\n",
    "                     )\n",
    "# 是否需要早停，当val_loss一直不下降的时候意味着模型基本训练完毕，可以停止\n",
    "early_stopping = EarlyStopping(\n",
    "                        monitor='val_loss', \n",
    "                        min_delta=0, \n",
    "                        patience=10, \n",
    "                        verbose=1\n",
    "                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 交叉熵\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "        optimizer = 'adam',\n",
    "        metrics = [Mean_IOU])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Runtime custom callbacks\n",
    "# %% https://github.com/deepsense-ai/intel-ai-webinar-neural-networks/blob/master/live_loss_plot.py\n",
    "# Fixed code to enable non-flat loss plots on keras model.fit_generator()\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "def translate_metric(x):\n",
    "    translations = {'acc': \"Accuracy\", 'loss': \"Log-loss (cost function)\"}\n",
    "    if x in translations:\n",
    "        return translations[x]\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "class PlotLosses(Callback):\n",
    "    def __init__(self, figsize=None):\n",
    "        super(PlotLosses, self).__init__()\n",
    "        self.figsize = figsize\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "\n",
    "        self.base_metrics = [metric for metric in self.params['metrics'] if not metric.startswith('val_')]\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs.copy())\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=self.figsize)\n",
    "\n",
    "        for metric_id, metric in enumerate(self.base_metrics):\n",
    "            plt.subplot(1, len(self.base_metrics), metric_id + 1)\n",
    "\n",
    "            plt.plot(range(1, len(self.logs) + 1),\n",
    "                     [log[metric] for log in self.logs],\n",
    "                     label=\"training\")\n",
    "            if self.params['do_validation']:\n",
    "                plt.plot(range(1, len(self.logs) + 1),\n",
    "                         [log['val_' + metric] for log in self.logs],\n",
    "                         label=\"validation\")\n",
    "            plt.title(translate_metric(metric))\n",
    "            plt.xlabel('epoch')\n",
    "            plt.legend(loc='center left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show();    \n",
    "\n",
    "plot_losses = PlotLosses(figsize=(16, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, val on 315 samples, with batch size 1.\n",
      "Epoch 1/45\n",
      "1263/1263 [==============================] - 789s 624ms/step - loss: 0.0850 - Mean_IOU: 0.6412 - val_loss: 0.0594 - val_Mean_IOU: 0.6081\n",
      "Epoch 2/45\n",
      "1263/1263 [==============================] - 746s 590ms/step - loss: 0.0334 - Mean_IOU: 0.7161 - val_loss: 0.0739 - val_Mean_IOU: 0.5891\n",
      "Epoch 3/45\n",
      "1263/1263 [==============================] - 747s 591ms/step - loss: 0.0298 - Mean_IOU: 0.7386 - val_loss: 0.0544 - val_Mean_IOU: 0.5894\n",
      "Epoch 4/45\n",
      "1263/1263 [==============================] - 747s 592ms/step - loss: 0.0279 - Mean_IOU: 0.7502 - val_loss: 0.0529 - val_Mean_IOU: 0.6292\n",
      "Epoch 5/45\n",
      "1263/1263 [==============================] - 747s 592ms/step - loss: 0.0257 - Mean_IOU: 0.7604 - val_loss: 0.0754 - val_Mean_IOU: 0.5791\n",
      "Epoch 6/45\n",
      "1263/1263 [==============================] - 747s 592ms/step - loss: 0.0227 - Mean_IOU: 0.7773 - val_loss: 0.0329 - val_Mean_IOU: 0.7613\n",
      "Epoch 7/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0217 - Mean_IOU: 0.7822 - val_loss: 0.0478 - val_Mean_IOU: 0.7094\n",
      "Epoch 8/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0221 - Mean_IOU: 0.7811 - val_loss: 0.1193 - val_Mean_IOU: 0.7018\n",
      "Epoch 9/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0212 - Mean_IOU: 0.7896 - val_loss: 0.0440 - val_Mean_IOU: 0.6806\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/45\n",
      "1263/1263 [==============================] - 748s 593ms/step - loss: 0.0181 - Mean_IOU: 0.8099 - val_loss: 0.0283 - val_Mean_IOU: 0.8115\n",
      "Epoch 11/45\n",
      "1263/1263 [==============================] - 748s 593ms/step - loss: 0.0173 - Mean_IOU: 0.8144 - val_loss: 0.0308 - val_Mean_IOU: 0.7534\n",
      "Epoch 12/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0169 - Mean_IOU: 0.8153 - val_loss: 0.0466 - val_Mean_IOU: 0.7913\n",
      "Epoch 13/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0166 - Mean_IOU: 0.8174 - val_loss: 0.0611 - val_Mean_IOU: 0.5951\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 14/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0154 - Mean_IOU: 0.8247 - val_loss: 0.0256 - val_Mean_IOU: 0.7932\n",
      "Epoch 15/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0146 - Mean_IOU: 0.8305 - val_loss: 0.0237 - val_Mean_IOU: 0.8135\n",
      "Epoch 16/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0143 - Mean_IOU: 0.8320 - val_loss: 0.0556 - val_Mean_IOU: 0.6456\n",
      "Epoch 17/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0144 - Mean_IOU: 0.8322 - val_loss: 0.0314 - val_Mean_IOU: 0.8178\n",
      "Epoch 18/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0136 - Mean_IOU: 0.8363 - val_loss: 0.0219 - val_Mean_IOU: 0.7934\n",
      "Epoch 19/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0133 - Mean_IOU: 0.8391 - val_loss: 0.0379 - val_Mean_IOU: 0.7580\n",
      "Epoch 20/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0132 - Mean_IOU: 0.8393 - val_loss: 0.0213 - val_Mean_IOU: 0.8040\n",
      "Epoch 21/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0128 - Mean_IOU: 0.8415 - val_loss: 0.0316 - val_Mean_IOU: 0.7878\n",
      "Epoch 22/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0124 - Mean_IOU: 0.8441 - val_loss: 0.0324 - val_Mean_IOU: 0.8062\n",
      "Epoch 23/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0124 - Mean_IOU: 0.8440 - val_loss: 0.0377 - val_Mean_IOU: 0.8118\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 24/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0118 - Mean_IOU: 0.8493 - val_loss: 0.0312 - val_Mean_IOU: 0.7940\n",
      "Epoch 25/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0114 - Mean_IOU: 0.8518 - val_loss: 0.0246 - val_Mean_IOU: 0.8049\n",
      "Epoch 26/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0112 - Mean_IOU: 0.8532 - val_loss: 0.0316 - val_Mean_IOU: 0.8104\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 27/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0108 - Mean_IOU: 0.8569 - val_loss: 0.0222 - val_Mean_IOU: 0.8187\n",
      "Epoch 28/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0107 - Mean_IOU: 0.8580 - val_loss: 0.0336 - val_Mean_IOU: 0.8204\n",
      "Epoch 29/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0106 - Mean_IOU: 0.8589 - val_loss: 0.0289 - val_Mean_IOU: 0.8063\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 30/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0104 - Mean_IOU: 0.8606 - val_loss: 0.0311 - val_Mean_IOU: 0.8130\n",
      "Epoch 31/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0103 - Mean_IOU: 0.8612 - val_loss: 0.0299 - val_Mean_IOU: 0.8156\n",
      "Epoch 32/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0103 - Mean_IOU: 0.8613 - val_loss: 0.0305 - val_Mean_IOU: 0.8136\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 33/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0102 - Mean_IOU: 0.8624 - val_loss: 0.0342 - val_Mean_IOU: 0.8150\n",
      "Epoch 34/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0101 - Mean_IOU: 0.8627 - val_loss: 0.0272 - val_Mean_IOU: 0.8149\n",
      "Epoch 35/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0101 - Mean_IOU: 0.8629 - val_loss: 0.0314 - val_Mean_IOU: 0.8168\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 36/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0101 - Mean_IOU: 0.8631 - val_loss: 0.0302 - val_Mean_IOU: 0.8172\n",
      "Epoch 37/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0100 - Mean_IOU: 0.8633 - val_loss: 0.0332 - val_Mean_IOU: 0.8140\n",
      "Epoch 38/45\n",
      "1263/1263 [==============================] - 747s 592ms/step - loss: 0.0100 - Mean_IOU: 0.8636 - val_loss: 0.0307 - val_Mean_IOU: 0.8161\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 39/45\n",
      "1263/1263 [==============================] - 746s 591ms/step - loss: 0.0100 - Mean_IOU: 0.8636 - val_loss: 0.0339 - val_Mean_IOU: 0.8168\n",
      "Epoch 40/45\n",
      "1263/1263 [==============================] - 747s 591ms/step - loss: 0.0100 - Mean_IOU: 0.8639 - val_loss: 0.0227 - val_Mean_IOU: 0.8192\n",
      "Epoch 41/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0100 - Mean_IOU: 0.8639 - val_loss: 0.0386 - val_Mean_IOU: 0.8094\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 42/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0100 - Mean_IOU: 0.8641 - val_loss: 0.0285 - val_Mean_IOU: 0.8206\n",
      "Epoch 43/45\n",
      "1263/1263 [==============================] - 749s 593ms/step - loss: 0.0100 - Mean_IOU: 0.8642 - val_loss: 0.0271 - val_Mean_IOU: 0.8080\n",
      "Epoch 44/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0100 - Mean_IOU: 0.8641 - val_loss: 0.0309 - val_Mean_IOU: 0.8200\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 45/45\n",
      "1263/1263 [==============================] - 748s 592ms/step - loss: 0.0100 - Mean_IOU: 0.8641 - val_loss: 0.0307 - val_Mean_IOU: 0.8135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22d9d85ff98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "    \n",
    "# 开始训练\n",
    "model.fit_generator(generate_arrays_from_file(lines[:num_train], batch_size),\n",
    "        steps_per_epoch=max(1, num_train//batch_size),\n",
    "        validation_data=generate_arrays_from_file(lines[num_train:], batch_size),\n",
    "        validation_steps=max(1, num_val//batch_size),\n",
    "        epochs=45,\n",
    "        initial_epoch=0,\n",
    "        callbacks=[checkpoint_period, reduce_lr])# plot_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "class_colors = [[0,0,0],[255,0,0],[0,255,0]]\n",
    "NCLASSES = 3\n",
    "HEIGHT = 832\n",
    "WIDTH = 832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = resnet50_unet(n_classes=NCLASSES,input_height=HEIGHT, input_width=WIDTH)\n",
    "model.load_weights(\"1.h5\")\n",
    "\n",
    "imgs = os.listdir(\"./img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for id_ in imgs:\n",
    "\n",
    "    img = Image.open(\"./img//\"+id_)\n",
    "    old_img = copy.deepcopy(img)\n",
    "    orininal_h = np.array(img).shape[0]\n",
    "    orininal_w = np.array(img).shape[1]\n",
    "\n",
    "    img = img.resize((WIDTH,HEIGHT))\n",
    "    img = np.array(img)\n",
    "    img = img/255\n",
    "    img = img.reshape(-1,HEIGHT,WIDTH,3)\n",
    "    pr = model.predict(img)[0]\n",
    "\n",
    "    pr = pr.reshape((int(HEIGHT/2), int(WIDTH/2),NCLASSES)).argmax(axis=-1)\n",
    "\n",
    "    seg_img = np.zeros((int(HEIGHT/2), int(WIDTH/2),3))\n",
    "    colors = class_colors\n",
    "\n",
    "    for c in range(NCLASSES):\n",
    "        seg_img[:,:,0] += ( (pr[:,: ] == c )*( colors[c][0] )).astype('uint8')\n",
    "        seg_img[:,:,1] += ((pr[:,: ] == c )*( colors[c][1] )).astype('uint8')\n",
    "        seg_img[:,:,2] += ((pr[:,: ] == c )*( colors[c][2] )).astype('uint8')\n",
    "\n",
    "    seg_img = Image.fromarray(np.uint8(seg_img)).resize((orininal_w,orininal_h))\n",
    "\n",
    "#     image = Image.blend(old_img,seg_img,0.3)\n",
    "#     image.save(\"./img_out/\"+id_)\n",
    "    seg_img.save(\"./img_out/\"+id_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
